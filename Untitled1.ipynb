{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "163Vwp8VrstTdaV9pQoDx_QgT0yKNX9Qv",
      "authorship_tag": "ABX9TyOt7tT1PKOUj9lEn24R8Zx1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Domco02/UIaN/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow tensorflow-datasets matplotlib\n"
      ],
      "metadata": {
        "id": "fVk4YXv3k_L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1t_N7VcWlDUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downscale(img, scale=2):\n",
        "    h, w = tf.shape(img)[0], tf.shape(img)[1]\n",
        "    new_h, new_w = h // scale, w // scale\n",
        "    return tf.image.resize(img, (new_h, new_w), method='area')"
      ],
      "metadata": {
        "id": "STROJIdKlE59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_psnr(hr, sr):\n",
        "    return tf.image.psnr(hr, sr, max_val=1.0)"
      ],
      "metadata": {
        "id": "RE2OFMi5lHKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_pair(lr_bic, sr, hr):\n",
        "    fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
        "    axes[0].imshow(np.clip(lr_bic,0,1)); axes[0].set_title('LR (bicubic up)')\n",
        "    axes[1].imshow(np.clip(sr,0,1)); axes[1].set_title('SR')\n",
        "    axes[2].imshow(np.clip(hr,0,1)); axes[2].set_title('HR')\n",
        "    for ax in axes: ax.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0xyXQbL2lIsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_shuffle(scale):\n",
        "    return layers.Lambda(lambda x: tf.nn.depth_to_space(x, scale))\n",
        "\n",
        "def build_simple_espcn(scale=2, channels=3):\n",
        "    x_in = layers.Input(shape=(None, None, channels))\n",
        "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x_in)\n",
        "    x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)\n",
        "    x = layers.Conv2D((scale**2)*channels, 3, padding='same')(x)\n",
        "    x = pixel_shuffle(scale)(x)\n",
        "    x = layers.Activation('sigmoid')(x)\n",
        "    return models.Model(x_in, x)\n",
        "\n",
        "model = build_simple_espcn(scale=2)\n",
        "model.compile(optimizer=optimizers.Adam(1e-3), loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "rJwP177SlKdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCALE = 2\n",
        "BATCH_SIZE = 3\n",
        "EPOCHS = 20  # krátky tréning pre rýchly test\n",
        "\n",
        "CROP_SIZE = 128  # výška a šírka cropu pre tréning\n",
        "\n",
        "def prepare_example(ex):\n",
        "    hr = tf.image.convert_image_dtype(ex['hr'], tf.float32)\n",
        "\n",
        "    # crop na pevný rozmer\n",
        "    hr = tf.image.random_crop(hr, size=[CROP_SIZE*SCALE, CROP_SIZE*SCALE, 3])\n",
        "\n",
        "    # zníženie rozlíšenia\n",
        "    lr_small = downscale(hr, SCALE)\n",
        "\n",
        "    return lr_small, hr\n",
        "\n",
        "ds_raw = tfds.load('div2k', split='train', as_supervised=False)\n",
        "\n",
        "# The prepare_example function from cell 5cGz5t8il30R will be used.\n",
        "ds = ds_raw.map(prepare_example)\n",
        "ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# --- FIX: Ensure the model is built with actual input shapes before training starts ---\n",
        "for lr_sample, _ in ds.take(1):\n",
        "    _ = model(lr_sample) # Call the model once on sample data to build its variables\n",
        "    break # Only need one sample to build"
      ],
      "metadata": {
        "id": "lymWJSaxlO31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b939ada"
      },
      "source": [
        "history = model.fit(ds, epochs=EPOCHS)\n",
        "print(\"Loss first/last:\", history.history[\"loss\"][0], history.history[\"loss\"][-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CROP_SIZE = 128  # výška a šírka cropu pre tréning"
      ],
      "metadata": {
        "id": "zbDzaXPhl3G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_example(ex):\n",
        "    hr = tf.image.convert_image_dtype(ex['hr'], tf.float32)\n",
        "\n",
        "    # crop na pevný rozmer\n",
        "    hr = tf.image.random_crop(hr, size=[CROP_SIZE*SCALE, CROP_SIZE*SCALE, 3])\n",
        "\n",
        "    # zníženie rozlíšenia\n",
        "    lr_small = downscale(hr, SCALE)\n",
        "\n",
        "    return lr_small, hr"
      ],
      "metadata": {
        "id": "5cGz5t8il30R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "847073d2"
      },
      "source": [
        "for lr_small, hr in ds.take(1):\n",
        "    sr = model.predict(lr_small)\n",
        "    print(\"SR min/max/mean:\", sr.min(), sr.max(), sr.mean())\n",
        "    print(\"LR min/max/mean:\", lr_small.numpy().min(), lr_small.numpy().max(), lr_small.numpy().mean())\n",
        "    print(\"HR min/max/mean:\", hr.numpy().min(), hr.numpy().max(), hr.numpy().mean())\n",
        "\n",
        "    for i in range(len(sr)):\n",
        "        lr_bic = tf.image.resize(lr_small[i], tf.shape(hr[i])[:2], method='bicubic')\n",
        "        show_pair(lr_bic.numpy(), sr[i], hr[i].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e8c6473"
      },
      "source": [
        "for lr_small, hr in ds.take(1):\n",
        "    sr = model.predict(lr_small)\n",
        "    print(\"SR min/max/mean:\", sr.min(), sr.max(), sr.mean())\n",
        "    print(\"LR min/max/mean:\", lr_small.numpy().min(), lr_small.numpy().max(), lr_small.numpy().mean())\n",
        "    print(\"HR min/max/mean:\", hr.numpy().min(), hr.numpy().max(), hr.numpy().mean())\n",
        "\n",
        "    for i in range(len(sr)):\n",
        "        lr_bic = tf.image.resize(lr_small[i], tf.shape(hr[i])[:2], method='bicubic')\n",
        "        show_pair(lr_bic.numpy(), sr[i], hr[i].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GKKqi50tZwjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f264626"
      },
      "source": [
        "for lr_small, hr in ds.take(1):\n",
        "    sr = model.predict(lr_small)\n",
        "    for i in range(len(sr)):\n",
        "        lr_bic = tf.image.resize(lr_small[i], tf.shape(hr[i])[:2], method='bicubic')\n",
        "        show_pair(lr_bic.numpy(), sr[i], hr[i].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lr_small, hr in ds.take(1):\n",
        "    sr = model.predict(lr_small)\n",
        "    print(\"SR min/max/mean:\", sr.min(), sr.max(), sr.mean())\n",
        "    print(\"LR min/max/mean:\", lr_small.numpy().min(), lr_small.numpy().max(), lr_small.numpy().mean())\n",
        "    print(\"HR min/max/mean:\", hr.numpy().min(), hr.numpy().max(), hr.numpy().mean())\n",
        "\n",
        "    for i in range(len(sr)):\n",
        "        lr_bic = tf.image.resize(lr_small[i], tf.shape(hr[i])[:2], method='bicubic')\n",
        "        show_pair(lr_bic.numpy(), sr[i], hr[i].numpy())"
      ],
      "metadata": {
        "id": "1Ob3bIfilSHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f1e660c"
      },
      "source": [
        "### Architektúra modelu `build_simple_espcn`\n",
        "\n",
        "Model je definovaný funkciou `build_simple_espcn(scale=2, channels=3)` a skladá sa z nasledujúcich vrstiev:\n",
        "\n",
        "1.  **`layers.Input`**: Vstupná vrstva, ktorá prijíma obrázky s nízkym rozlíšením. Jej tvar (`shape`) je nastavený na `(None, None, channels)`, čo znamená, že môže prijímať obrázky akejkoľvek výšky a šírky, ale s fixným počtom kanálov (typicky 3 pre RGB).\n",
        "\n",
        "2.  **`layers.Conv2D(32, 3, activation='relu', padding='same')`**: Prvá konvolučná vrstva:\n",
        "    *   **`32`**: Počet filtrov (feature maps).\n",
        "    *   **`3`**: Veľkosť jadra filtra (3x3).\n",
        "    *   **`activation='relu'`**: Používa aktivačnú funkciu ReLU, ktorá pomáha modelu učiť sa nelineárne vlastnosti.\n",
        "    *   **`padding='same'`**: Zabezpečuje, že výška a šírka výstupu z tejto vrstvy sú rovnaké ako vstup (za predpokladu stride=1).\n",
        "\n",
        "3.  **`layers.Conv2D(16, 3, activation='relu', padding='same')`**: Druhá konvolučná vrstva s menším počtom filtrov (16), ale rovnakou veľkosťou jadra a aktivačnou funkciou. Táto vrstva ďalej spracováva črty získané z predchádzajúcej vrstvy.\n",
        "\n",
        "4.  **`layers.Conv2D((scale**2)*channels, 3, padding='same')`**: Tretia konvolučná vrstva. Toto je kľúčová vrstva pre sub-pixelovú konvolúciu:\n",
        "    *   **`(scale**2)*channels`**: Počet filtrov je nastavený na `(mierka^2) * počet_kanálov`. Napríklad, ak `scale=2` a `channels=3`, bude to `(2^2)*3 = 12` filtrov. Tieto filtre generujú výstup, ktorý bude neskôr reorganizovaný na obrázok s vyšším rozlíšením.\n",
        "    *   **`3`**: Veľkosť jadra filtra (3x3).\n",
        "    *   **`padding='same'`**: Udržiava rozmery výstupu rovnaké ako vstupu.\n",
        "\n",
        "5.  **`pixel_shuffle(scale)`**: Táto vrstva je implementovaná pomocou `layers.Lambda(lambda x: tf.nn.depth_to_space(x, scale))`. Je to jadro ESPCN architektúry. Funkcia `tf.nn.depth_to_space` presúva pixely z priestorovej dimenzie na hĺbkovú dimenziu (kanály) a naopak, čo efektívne zvyšuje rozlíšenie obrázka. Ak bol vstup do tejto vrstvy napríklad obrázok 64x64 s 12 kanálmi (pre `scale=2`, `channels=3`), výstupom bude obrázok 128x128 s 3 kanálmi, čím sa efektívne zvýši rozlíšenie bez tradičnej upsampling operácie (ako je bilineárna alebo bikubická interpolácia), ktorá by len zväčšila pixely.\n",
        "\n",
        "6.  **`layers.Activation('sigmoid')`**: Posledná aktivačná vrstva Sigmoid. Táto funkcia škáluje hodnoty pixelov výstupného obrázka do rozsahu [0, 1], čo je typické pre obrázky, ktoré sa následne spracovávajú ako float32 a reprezentujú intenzitu pixelov.\n",
        "\n",
        "**Zhrnutie toku dát:**\n",
        "\n",
        "Model prijíma obrázok s nízkym rozlíšením (LR), extrahuje z neho črty pomocou prvých dvoch konvolučných vrstiev. Tretia konvolučná vrstva generuje \"predpovede\" pixelov pre vyššie rozlíšenie, ktoré sú \"zbalené\" do hĺbkovej dimenzie. Následne vrstva `pixel_shuffle` \"rozbalí\" tieto pixely a usporiada ich do požadovaného vysokého rozlíšenia. Nakoniec, Sigmoid zabezpečí, že výstup je v platnom rozsahu pre obrázky."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4991471c"
      },
      "source": [
        "psnr_values = []\n",
        "num_samples = 0\n",
        "\n",
        "for lr_small, hr in ds:\n",
        "    sr = model.predict(lr_small, verbose=0)\n",
        "    # Ensure both hr and sr are float32 in range [0, 1]\n",
        "    # hr is already in [0, 1] due to prepare_example\n",
        "    # sr is in [0, 1] due to sigmoid activation\n",
        "\n",
        "    for i in range(len(sr)):\n",
        "        current_psnr = compute_psnr(hr[i], sr[i])\n",
        "        psnr_values.append(current_psnr.numpy())\n",
        "    num_samples += len(sr)\n",
        "\n",
        "if psnr_values:\n",
        "    average_psnr = np.mean(psnr_values)\n",
        "    print(f\"Priemerná PSNR na {num_samples} vzorkách: {average_psnr:.2f}\")\n",
        "else:\n",
        "    print(\"Žiadne vzorky na vyhodnotenie PSNR.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cb0971e"
      },
      "source": [
        "ssim_values = []\n",
        "num_samples_ssim = 0\n",
        "\n",
        "for lr_small, hr in ds:\n",
        "    sr = model.predict(lr_small, verbose=0)\n",
        "    # Ensure both hr and sr are float32 in range [0, 1]\n",
        "    # hr is already in [0, 1] due to prepare_example\n",
        "    # sr is in [0, 1] due to sigmoid activation\n",
        "\n",
        "    for i in range(len(sr)):\n",
        "        current_ssim = tf.image.ssim(hr[i], sr[i], max_val=1.0)\n",
        "        ssim_values.append(current_ssim.numpy())\n",
        "    num_samples_ssim += len(sr)\n",
        "\n",
        "if ssim_values:\n",
        "    average_ssim = np.mean(ssim_values)\n",
        "    print(f\"Priemerná SSIM na {num_samples_ssim} vzorkách: {average_ssim:.4f}\")\n",
        "else:\n",
        "    print(\"Žiadne vzorky na vyhodnotenie SSIM.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0caa10a4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MAE)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3f0b96f"
      },
      "source": [
        "model.save('simple_espcn_model.keras')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d01fba72"
      },
      "source": [
        "Model bol úspešne uložený do súboru `simple_espcn_model.keras`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "723401fa"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Nahrajte svoje obrázky (napríklad .jpg, .png).\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a2eae01"
      },
      "source": [
        "Po nahraní obrázkov by ste museli upraviť časť kódu, ktorá načítava dataset `div2k`. Namiesto `tfds.load('div2k')` by ste museli načítať svoje obrázky. Napríklad, ak máte obrázky v priečinku `/content/my_images/` a chcete načítať jeden konkrétny obrázok:\n",
        "\n",
        "```python\n",
        "# Príklad načítania jedného vlastného obrázka\n",
        "# filepath = '/content/my_image.png' # Upravte cestu k vášmu obrázku\n",
        "# custom_image_hr = tf.io.read_file(filepath)\n",
        "# custom_image_hr = tf.image.decode_image(custom_image_hr, channels=3)\n",
        "\n",
        "# Ak by ste chceli spracovať viacero obrázkov a vytvoriť z nich dataset,\n",
        "# museli by ste zozbierať cesty k súborom a potom ich mapovať cez funkciu.\n",
        "# Napríklad, ak nahraté obrázky majú rovnakú veľkosť a môžete ich priamo použiť:\n",
        "\n",
        "# Zatiaľ pre ukážku vezmeme jeden z nahraných obrázkov\n",
        "# Prispôsobte si to podľa toho, koľko a aké obrázky chcete testovať\n",
        "first_uploaded_file = next(iter(uploaded.keys()))\n",
        "filepath = f'/content/{first_uploaded_file}'\n",
        "\n",
        "hr_img = tf.io.read_file(filepath)\n",
        "hr_img = tf.image.decode_image(hr_img, channels=3)\n",
        "hr_img = tf.image.convert_image_dtype(hr_img, tf.float32)\n",
        "\n",
        "# Pripravíme obrázok pre model (downscale, crop ak je príliš veľký atď.)\n",
        "# Pre jeden obrázok nemusíme použiť random_crop, ale môžeme ho len zmenšiť\n",
        "# Model očakáva dávku obrázkov, takže musíme pridať dimenziu dávky\n",
        "\n",
        "# Uistite sa, že obrázok má rovnakú škálu, akú očakáva model\n",
        "# Ak je obrázok už HR, tak ho len zmenšíme na LR\n",
        "\n",
        "# Ak je váš obrázok príliš veľký pre CROP_SIZE, môžete ho najprv zmenšiť:\n",
        "# hr_img = tf.image.resize(hr_img, [CROP_SIZE * SCALE, CROP_SIZE * SCALE])\n",
        "\n",
        "lr_custom = downscale(hr_img, SCALE)\n",
        "lr_custom = tf.expand_dims(lr_custom, axis=0) # Pridajte dávkovú dimenziu\n",
        "\n",
        "# Vykonajte super-rozlíšenie pomocou vášho trénovaného modelu\n",
        "sr_custom = model.predict(lr_custom)\n",
        "\n",
        "# Pre vizualizáciu:\n",
        "lr_bicubic_custom = tf.image.resize(lr_custom[0], tf.shape(hr_img)[:2], method='bicubic')\n",
        "show_pair(lr_bicubic_custom.numpy(), sr_custom[0], hr_img.numpy())\n",
        "\n",
        "# Môžete tiež vypočítať PSNR pre váš vlastný obrázok\n",
        "psnr_value = compute_psnr(hr_img, sr_custom[0])\n",
        "print(f\"PSNR pre vlastný obrázok: {psnr_value.numpy():.2f}\")\n",
        "```\n",
        "\n",
        "**Dôležité body, na ktoré treba pamätať:**\n",
        "\n",
        "*   **Formát obrázka**: Uistite sa, že vaše nahrané obrázky sú v podporovanom formáte (napr. JPG, PNG).\n",
        "*   **Rozmery**: `tf.image.random_crop` vo funkcii `prepare_example` očakáva, že vstupný obrázok je dostatočne veľký na vykonanie orezania. Ak sú vaše obrázky menšie, mali by ste túto časť kódu prispôsobiť.\n",
        "*   **`CROP_SIZE` a `SCALE`**: Ak boli vaše vlastné obrázky pripravené inak ako s pôvodnými `CROP_SIZE` a `SCALE` hodnotami, môžete ich potrebovať upraviť alebo model pretrénovať.\n",
        "*   **Dávkovanie**: Váš model očakáva vstup vo forme dávky (batch). Pre jeden obrázok pridajte dimenziu dávky pomocou `tf.expand_dims(image, axis=0)`.\n",
        "\n"
      ]
    }
  ]
}